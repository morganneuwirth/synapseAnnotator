{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from oiffile import imread\n",
    "import random\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import matplotlib\n",
    "import glob\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "import scipy.io as sio\n",
    "import matplotlib.patches as patches\n",
    "from skimage.measure import label,regionprops\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from skimage.transform import rescale\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os, os.path\n",
    "from skimage.draw import circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary masks\n",
    "def make_labels(img,ys,xs,radius=4):\n",
    "    labels = np.zeros(img.shape[1:])\n",
    "    for xv,yv in zip(xs,ys):\n",
    "        rr,cc = circle(xv,yv,radius,labels.shape)\n",
    "        \n",
    "        labels[rr,cc]=1\n",
    "    return labels\n",
    "\n",
    "# training images\n",
    "def make_training_set(labels,indexes):\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    for i in indexes:\n",
    "        if len(labels[i])==0:\n",
    "            d = np.zeros_like(collman[0,0,:,:])\n",
    "        else:\n",
    "            d = make_labels(collman[:,0],np.array(labels[i])[:,0],np.array(labels[i])[:,1])\n",
    "        train_images.append(collman[:,i])\n",
    "        train_labels.append(d)\n",
    "    return train_images,train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image number\n",
    "i = 1\n",
    "# generate image name\n",
    "if i<10:\n",
    "    n = '000%s' % (i)\n",
    "elif i <100:\n",
    "    n = '00%s' % (i)\n",
    "else:\n",
    "    n = '0%s' % (i)\n",
    "\n",
    "fdir = r'E:\\pcp2cre_syptom_568_mglur1_1to200_647_1to250_vgat_1to200_488_1to250\\FV10__20190507_224650_flocculusA/Track%s' % (n)\n",
    "# open image\n",
    "im_name = 'Image%s_01.oib' % (n)\n",
    "image = imread(os.path.join(fdir,im_name))\n",
    "file_name= 'Track%s' % (n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# randomly select z-slice to annnotate\n",
    "z_slice=random.randint(0,15)\n",
    "print(z_slice)\n",
    "\n",
    "if z_slice < 10:\n",
    "    v1 = str(z_slice)\n",
    "    v = '0%s' % (v1)\n",
    "else:\n",
    "    v = str(z_slice)\n",
    "\n",
    "# open a txt file for logging annotation\n",
    "annotation_filename = \"%s_%s\\n\" % (file_name,v)\n",
    "with open(\"../../datasets/flocculusA/imagesUsed-flocculusA.txt\", \"a\") as fin:\n",
    "    fin.write(annotation_filename)\n",
    "\n",
    "# load and clip pre-computed medians of slices\n",
    "medianTotal= np.double(np.load(\"../../datasets/flocculusA/normalizationMatrices/medianTotal.npy\"))\n",
    "medianclipped0 = np.maximum(medianTotal[0],np.max(medianTotal[0])/3)\n",
    "medianclipped1 = np.maximum(medianTotal[1],np.max(medianTotal[1])/3)\n",
    "medianclipped2 = np.maximum(medianTotal[2],np.max(medianTotal[2])/3)\n",
    "\n",
    "# make two copies of image for the selected slice\n",
    "image_save = np.double(image[:,z_slice,:,:].transpose(1,2,0))\n",
    "image_view = np.double(image[:,z_slice,:,:].transpose(1,2,0))\n",
    "# normalize the image used for view\n",
    "image_view[:,:,0] = image_view[:,:,0]/medianTotal[0][z_slice]\n",
    "image_view[:,:,1] = image_view[:,:,1]/medianTotal[1][z_slice]\n",
    "image_view[:,:,2] = 0\n",
    "# normalize the image used for saving\n",
    "image_save[:,:,0] = image_save[:,:,0]/medianclipped0[z_slice]\n",
    "image_save[:,:,1] = image_save[:,:,1]/medianclipped1[z_slice]\n",
    "image_save[:,:,2] = image_save[:,:,2]/medianclipped2[z_slice]\n",
    "pt=[]\n",
    "# manually anotate the selected image\n",
    "%matplotlib inline\n",
    "%matplotlib qt\n",
    "plt.figure(figsize=(30,30))\n",
    "plt.imshow(image_view[:,:,1])\n",
    "plt.show()\n",
    "pt = np.asarray(plt.ginput(150,timeout = -1))\n",
    "\n",
    "# save raw coordinates\n",
    "rawStr=\"../../datasets/flocculusA/rawCoordinates/%s_%s_rawCoords.npy\" % (file_name,v)\n",
    "np.savetxt(rawStr, pt)\n",
    "# resize and cut image into 4 smaller images with overlapping segments \n",
    "image_save = resize(image_save,(400,400), order=1, preserve_range=True)\n",
    "h=400\n",
    "w=400\n",
    "tol=30\n",
    "\n",
    "UL=(image_save[0:int(h/2+tol),0:int(w/2+tol),:])       \n",
    "UR=(image_save[0:int(h/2+tol),int(w/2-tol):w,:])\n",
    "LL=(image_save[int(h/2-tol):h,0:int(w/2+tol),:])\n",
    "LR=(image_save[int(h/2-tol):h,int(w/2-tol):w,:])   \n",
    "smallPictures=[UL,UR,LL,LR]\n",
    "\n",
    "# sort coordinates of four smaller images\n",
    "b = [[] for i in range(0,4)]    \n",
    "for j in pt:\n",
    "    if j[0] < 460 and j[1] < 460:\n",
    "        point = np.copy(j)\n",
    "        (b[0]).append(.5*np.array(point))\n",
    "\n",
    "    if j[0] > 340 and j[1] < 460:\n",
    "        point = np.copy(j)\n",
    "        point[0]=point[0]-340\n",
    "        (b[1]).append(.5*np.array(point))\n",
    "      \n",
    "    if j[0] < 460 and j[1] > 340:\n",
    "        point = np.copy(j)\n",
    "        point[1]=point[1]-340\n",
    "        (b[2]).append(.5*np.array(point))\n",
    "        \n",
    "    if j[0] > 340 and j[1] > 340:\n",
    "        point = np.copy(j)\n",
    "        point[0]=point[0]-340\n",
    "        point[1]=point[1]-340\n",
    "        (b[3]).append(.5*np.array(point))\n",
    "\n",
    "collman = np.transpose((np.stack(smallPictures,axis=3)),(2,3,0,1))\n",
    "train_images,train_labels = make_training_set(b,range(0,4))\n",
    "smallPicturesNames=['UL','UR','LL','LR']\n",
    "# save individual training images, training masks, and coordinates\n",
    "for j in range(0,4): \n",
    "    coordsStr=\"../../datasets/flocculusA/trainingCoordinates/%s_%s_%s_coords\" % (file_name,v,smallPicturesNames[j])\n",
    "    maskStr=\"../../datasets/flocculusA/trainingMasks/%s_%s_%s_mask.npy\" % (file_name,v,smallPicturesNames[j])\n",
    "    imageStr=\"../../datasets/flocculusA/trainingImages/%s_%s_%s_image.npy\" % (file_name,v,smallPicturesNames[j])\n",
    "    np.save(maskStr, train_labels[j])\n",
    "    np.save(imageStr, train_images[j])\n",
    "    np.savetxt(coordsStr, b[j], delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
