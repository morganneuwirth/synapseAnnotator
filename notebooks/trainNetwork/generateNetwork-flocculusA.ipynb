{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from imshowpair import imshowpair\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from oiffile import imread\n",
    "import random\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import matplotlib\n",
    "import glob\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from other import dognet\n",
    "from other import functions\n",
    "from other.dognet.unet import *\n",
    "import scipy.io as sio\n",
    "import matplotlib.patches as patches\n",
    "from skimage.measure import label,regionprops\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from skimage.transform import rescale\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os, os.path\n",
    "%matplotlib inline\n",
    "from skimage.draw import circle\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training masks\n",
    "path1 = glob.glob(\"../../datasets/flocculusA/trainingMasks/*.npy\")\n",
    "trainingMasks = functions.get_trainingMasks(path1)\n",
    "# get and scale training images\n",
    "path2 = glob.glob(\"../../datasets/flocculusA/trainingImages/*.npy\")\n",
    "trainingImages,collman = functions.get_trainingImages(path2,20,25,25)\n",
    "\n",
    "# randomly divide into training and testing images\n",
    "rndsplit = np.random.permutation(len(trainingImages))\n",
    "numTest = int(len(trainingImages)/4)\n",
    "numTrain = int(len(trainingImages)-numTest)\n",
    "imagestraining = rndsplit[:numTrain]\n",
    "imagestesting = rndsplit[numTrain:]\n",
    "\n",
    "newTrainingImages=[]\n",
    "newTrainingMasks=[]\n",
    "newTestingImages=[]\n",
    "newTestingMasks=[]\n",
    "\n",
    "for i in imagestraining:\n",
    "    newTrainingImages.append(trainingImages[i])\n",
    "    newTrainingMasks.append(trainingMasks[i])\n",
    "for j in imagestesting:  \n",
    "    newTestingImages.append(trainingImages[j])\n",
    "    newTestingMasks.append(trainingMasks[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train network\n",
    "lossFn = \"sd\"\n",
    "alpha = 0.5\n",
    "gamma = 1\n",
    "lrs = 1e-4\n",
    "batchSize = 2\n",
    "nEpoch = 1200\n",
    "dschedule = [50,0.98]\n",
    "\n",
    "device = torch.device('cuda')\n",
    "net = UNet(3,2).to(device)\n",
    "net,train_errors,test_errors,visual_test=dognet.train_routine(net,dognet.create_generator(newTrainingImages,newTrainingMasks,device = device,batch_size = batchSize),dognet.create_generator(newTestingImages,newTestingMasks,device = device,batch_size = batchSize,transform=False),n_train_samples = numTrain, n_test_samples=numTest,n_epoch=nEpoch,batch_size=batchSize,loss=lossFn,lr=lrs,alpha = alpha,decay_schedule = dschedule,gamma = gamma,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save network\n",
    "torch.save(net, 'netName')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view training and testing errors\n",
    "plt.plot(train_errors)\n",
    "plt.plot(test_errors)\n",
    "plt.ylim((0,max(train_errors)))\n",
    "plt.legend([\"training\", \"testing\"])\n",
    "plt.title(\"Softdice Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# view training image, predicted synapses, and manually annotated mask\n",
    "for selidx in range(0,numTest,2):\n",
    "    if np.sum(newTestingMasks[selidx])>0:\n",
    "        plt.figure(figsize=(9,3))\n",
    "        inimg = np.transpose(resize(np.transpose(newTestingImages[selidx],(1,2,0)),(230,230)),(2,0,1))\n",
    "        outimg = functions.inference(net.to(torch.device(\"cpu\")),inimg,get_inter=False,device=torch.device(\"cpu\"))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(np.clip(np.transpose(newTestingImages[selidx],(1,2,0)),0,1))\n",
    "        plt.clim(0,1)\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(outimg[0])\n",
    "        plt.clim(0,1)\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(newTestingMasks[selidx])\n",
    "        plt.clim(0,1)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view synapse detection on a test image over epochs\n",
    "nums = np.arange(0,nEpoch,100)\n",
    "for x in nums:\n",
    "    plt.imshow(visual_test[x].detach().numpy())\n",
    "    plt.clim(0,1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted test image pver epochs as gif\n",
    "images=[]\n",
    "for x in range(0, int(800/5)):\n",
    "    images.append((visual_test[5*x].detach().numpy()))\n",
    "imageio.mimsave('flocAnet.gif', images, fps = 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
