{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from imshowpair import imshowpair\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from oiffile import imread\n",
    "import random\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import matplotlib\n",
    "import glob\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from other import dognet\n",
    "from other import functions\n",
    "from other.dognet.unet import *\n",
    "import scipy.io as sio\n",
    "import matplotlib.patches as patches\n",
    "from skimage.measure import label,regionprops\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from skimage.transform import rescale\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os, os.path\n",
    "%matplotlib inline\n",
    "from skimage.draw import circle\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training masks\n",
    "path1 = glob.glob(\"../../../datasets/vermisB/trainingMasks/*.npy\")\n",
    "trainingMasks = functions.get_trainingMasks(path1)\n",
    "# get and scale training images\n",
    "path2 = glob.glob(\"../../../datasets/vermisB/trainingImages/*.npy\")\n",
    "trainingImages,collman = functions.get_trainingImages(path2,20,22,25)\n",
    "\n",
    "# randomly divide into training and testing images\n",
    "rndsplit = np.random.permutation(len(trainingImages))\n",
    "numTest = int(len(trainingImages)/4)\n",
    "numTrain = int(len(trainingImages)-numTest)\n",
    "imagestraining = rndsplit[:numTrain]\n",
    "imagestesting = rndsplit[numTrain:]\n",
    "\n",
    "newTrainingImages=[]\n",
    "newTrainingMasks=[]\n",
    "newTestingImages=[]\n",
    "newTestingMasks=[]\n",
    "\n",
    "for i in imagestraining:\n",
    "    newTrainingImages.append(trainingImages[i])\n",
    "    newTrainingMasks.append(trainingMasks[i])\n",
    "for j in imagestesting:  \n",
    "    newTestingImages.append(trainingImages[j])\n",
    "    newTestingMasks.append(trainingMasks[j])\n",
    "    \n",
    "lossFn = \"sd\"\n",
    "alpha = 0.5\n",
    "gamma = 1\n",
    "lrs = 1e-4\n",
    "batchSize = 2\n",
    "nEpoch = 1200\n",
    "dschedule = [50,0.98]\n",
    "# save networks, losses, and test images over epochs\n",
    "networks = []\n",
    "trainingLoss = []\n",
    "testingLoss = []\n",
    "visualTests = []\n",
    "print(\"training images:\")\n",
    "print(imagestraining)\n",
    "print(\"testing images:\")\n",
    "print(imagestesting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 10 networks\n",
    "for i in range(0,10):\n",
    "    # train network\n",
    "    device = torch.device('cuda')\n",
    "    net = UNet(3,2).to(device)\n",
    "    net,train_errors,test_errors,visual_test=dognet.train_routine(net,dognet.create_generator(newTrainingImages,newTrainingMasks,device = device,batch_size = batchSize),dognet.create_generator(newTestingImages,newTestingMasks,device = device,batch_size = batchSize,transform=False),n_train_samples = numTrain, n_test_samples=numTest,n_epoch=nEpoch,batch_size=batchSize,loss=lossFn,lr=lrs,alpha = alpha,decay_schedule = dschedule,gamma = gamma,device = device)\n",
    "    \n",
    "    networks.append(net)\n",
    "    del net\n",
    "    trainingLoss.append(train_errors)\n",
    "    testingLoss.append(test_errors)\n",
    "    new_visual_test=[]\n",
    "    # save test image every 5 epochs\n",
    "    for x in range(0, int(1200/5)):\n",
    "        new_visual_test.append(visual_test[5*x])\n",
    "    visualTests.append(new_visual_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view test image, average predicted mask, annotated mask\n",
    "for selidx in range(0,numTest,1):\n",
    "    if np.sum(newTestingMasks[selidx])>0:\n",
    "        plt.figure(figsize=(9,3))\n",
    "        inimg = np.transpose(resize(np.transpose(newTestingImages[selidx],(1,2,0)),(230,230)),(2,0,1))\n",
    "        ims = []\n",
    "        for netnum in range(0,10):\n",
    "            outname = functions.inference(networks[netnum].to(torch.device(\"cuda\")),inimg,get_inter=False,device=torch.device(\"cuda\"))\n",
    "            ims.append(outname)\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(np.clip(np.transpose(newTestingImages[selidx],(1,2,0)),0,1))\n",
    "        plt.clim(0,1)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(np.median(np.asarray(ims)[:,0,:,:], axis=0),cmap='gray')\n",
    "        plt.clim(0,.8)\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(newTestingMasks[selidx],cmap='gray')\n",
    "        plt.clim(0,1)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save networks\n",
    "for i in range(0,10):\n",
    "    nsave = networks[i]\n",
    "    name = \"../networks/multipleNetworks-vermisB/net%s\" % (i)\n",
    "    torch.save(nsave, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view test and training error graphs\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(nEpoch+1),np.asarray(trainingLoss).T,'grey')\n",
    "plt.plot(np.arange(nEpoch+1),np.mean(np.asarray(trainingLoss).T,1),'r-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Softdice Loss')\n",
    "plt.title(\"Training Loss\")\n",
    "plt.ylim(0,0.005)\n",
    "plt.xlim(0,nEpoch)\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(nEpoch+1),np.asarray(testingLoss).T,'grey')\n",
    "plt.plot(np.arange(nEpoch+1),np.mean(np.asarray(testingLoss).T,1),'b-')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Softdice Loss')\n",
    "plt.title(\"Testing Loss\")\n",
    "plt.ylim(0,0.005)\n",
    "plt.xlim(0,nEpoch)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view average test and training loss\n",
    "plt.figure(figsize=(5.5,4))\n",
    "plt.plot(np.arange(nEpoch+1),np.mean(np.asarray(trainingLoss).T,1),'r-',label='training')\n",
    "plt.plot(np.arange(nEpoch+1),np.mean(np.asarray(testingLoss).T,1),'b-',label='testing')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Softdice Loss')\n",
    "plt.title(\"Training and Testing Losses\")\n",
    "plt.ylim(0,0.005)\n",
    "plt.xlim(0,nEpoch)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save gif of predicted mask of average test image over epochs\n",
    "images =[]\n",
    "for j in range(0,240):\n",
    "    ims = []\n",
    "    for i in range(0,10):\n",
    "        ims.append(visualTests[i][j])\n",
    "    images.append(( (sum(ims)/len(ims)) .detach().numpy()))\n",
    "    \n",
    "imageio.mimsave('gifName.gif', images, fps = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
