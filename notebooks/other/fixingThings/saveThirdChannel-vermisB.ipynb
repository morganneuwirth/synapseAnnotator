{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from oiffile import imread\n",
    "from PIL import Image\n",
    "import random\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "import matplotlib\n",
    "import glob\n",
    "import torch\n",
    "import sys\n",
    "import scipy.io as sio\n",
    "import matplotlib.patches as patches\n",
    "from skimage.measure import label,regionprops\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from skimage.transform import rescale\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_training_set(indexes):\n",
    "    train_images = []\n",
    "    for i in indexes:\n",
    "        train_images.append(collman[:,i])\n",
    "    return train_images\n",
    "\n",
    "medianTotal= np.double(np.load(\"../../datasets/vermisB/medianTotal.npy\"))\n",
    "meanTotal= np.double(np.load(\"../../datasets/vermisB/meanTotal.npy\"))\n",
    "\n",
    "medianclipped0 = np.maximum(medianTotal[0],np.max(medianTotal[0])*0.6)\n",
    "medianclipped1 = np.maximum(medianTotal[1],np.max(medianTotal[1])*0.6)\n",
    "medianclipped2 = np.maximum(meanTotal[2],np.max(meanTotal[2])*0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../datasets/vermisB/imagesUsed-vermisB.txt\") as fin:\n",
    "    lines = fin.readlines()\n",
    "    \n",
    "for num in range(0,len(lines)):\n",
    "    fname = lines[num]\n",
    "    fname = fname[:12]\n",
    "    v = fname[10:]\n",
    "    n = fname[5:9]\n",
    "    \n",
    "    z_slice = int(v)\n",
    "\n",
    "    fdir = r'E:\\pcp2cre_syptom_568_mglur1_1to200_647_1to250_vgat_1to200_488_1to250\\FV10__20190508_202030_vermisB\\Track%s' % (n)\n",
    "    \n",
    "    im_name = 'Image%s_01.oib' % (n)\n",
    "    image = imread(os.path.join(fdir,im_name))\n",
    "    file_name= 'Track%s' % (n)\n",
    "    \n",
    "    image_save = np.double(image[:,z_slice,:,:].transpose(1,2,0))\n",
    "    image_save[:,:,0] = image_save[:,:,0]/medianclipped0[z_slice]\n",
    "    image_save[:,:,1] = image_save[:,:,1]/medianclipped1[z_slice]\n",
    "    image_save[:,:,2] = image_save[:,:,2]/medianclipped2[z_slice]\n",
    "\n",
    "    image_save = resize(image_save,(400,400), order=1, preserve_range=True)\n",
    "\n",
    "    h=400\n",
    "    w=400\n",
    "    tol=30\n",
    "\n",
    "    UL=(image_save[0:int(h/2+tol),0:int(w/2+tol),:])       \n",
    "    UR=(image_save[0:int(h/2+tol),int(w/2-tol):w,:])\n",
    "    LL=(image_save[int(h/2-tol):h,0:int(w/2+tol),:])\n",
    "    LR=(image_save[int(h/2-tol):h,int(w/2-tol):w,:])\n",
    "\n",
    "    smallPictures=[UL,UR,LL,LR]\n",
    "\n",
    "    collman = np.transpose((np.stack(smallPictures,axis=3)),(2,3,0,1))\n",
    "    train_images = make_training_set(range(0,4))\n",
    "\n",
    "    smallPicturesNames=['UL','UR','LL','LR']\n",
    "\n",
    "    for j in range(0,4): \n",
    "        imageStr=\"../../datasets/vermisB/NEWtrainingImages/%s_%s_%s_image.npy\" % (file_name,v,smallPicturesNames[j])\n",
    "        np.save(imageStr, train_images[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
